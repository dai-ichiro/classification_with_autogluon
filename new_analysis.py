import json
import pandas as pd
import numpy as np
from collections import defaultdict
import statistics

class HPODataExtractor:
    """HPOå®Ÿé¨“çµæœã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºãƒ»åˆ†æã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, json_file_path):
        """
        Args:
            json_file_path (str): å®Ÿé¨“çµæœJSONãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        """
        self.json_file_path = json_file_path
        self.data = None
        self.trials_df = None
        
    def load_data(self):
        """JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        try:
            with open(self.json_file_path, 'r', encoding='utf-8') as f:
                self.data = json.load(f)
            print(f"âœ“ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ: {self.json_file_path}")
            return True
        except Exception as e:
            print(f"âœ— ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return False
    
    def extract_trials_data(self):
        """å…¨è©¦è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦DataFrameã«å¤‰æ›"""
        if not self.data:
            print("ã¾ãšload_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return None
        
        trials = []
        
        for i, trial_data in enumerate(self.data['trial_data']):
            try:
                # è¨­å®šãƒ‡ãƒ¼ã‚¿ã¨çµæœãƒ‡ãƒ¼ã‚¿ã‚’å€‹åˆ¥ã«ãƒ‘ãƒ¼ã‚¹
                trial_config = json.loads(trial_data[0])
                trial_results = json.loads(trial_data[1])
                
                # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                trial_info = {
                    'trial_id': trial_config['trial_id'],
                    'status': trial_config['status'],
                    
                    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
                    'learning_rate': trial_config['config']['optim.lr'],
                    'optimizer': trial_config['config']['optim.optim_type'],
                    'batch_size': trial_config['config']['env.batch_size'],
                    'max_epochs': trial_config['config']['optim.max_epochs'],
                    'model_name': trial_config['config']['model.timm_image.checkpoint_name'],
                    
                    # çµæœ
                    'final_roc_auc': trial_results['last_result']['val_roc_auc'],
                    'training_time_s': trial_results['last_result']['time_total_s'],
                    'final_iteration': trial_results['last_result']['training_iteration'],
                    
                    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹çµ±è¨ˆ
                    'avg_roc_auc': trial_results['metric_analysis']['val_roc_auc']['avg'],
                    'max_roc_auc': trial_results['metric_analysis']['val_roc_auc']['max'],
                    'min_roc_auc': trial_results['metric_analysis']['val_roc_auc']['min'],
                    
                    # æ™‚é–“çµ±è¨ˆ
                    'avg_time_per_iter': trial_results['metric_analysis']['time_this_iter_s']['avg'],
                    'max_time_per_iter': trial_results['metric_analysis']['time_this_iter_s']['max'],
                    'min_time_per_iter': trial_results['metric_analysis']['time_this_iter_s']['min'],
                }
                
                trials.append(trial_info)
                
            except Exception as e:
                print(f"è©¦è¡Œ {i} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")
                continue
        
        self.trials_df = pd.DataFrame(trials)
        print(f"âœ“ {len(trials)} è©¦è¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")
        return self.trials_df
    
    def get_summary(self):
        """å®Ÿé¨“ã®è¦ç´„çµ±è¨ˆã‚’è¡¨ç¤º"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("\n" + "="*60)
        print("HPOå®Ÿé¨“çµæœã‚µãƒãƒªãƒ¼")
        print("="*60)
        print(f"è©¦è¡Œæ•°: {len(self.trials_df)}")
        
        if 'start_time' in self.data.get('stats', {}):
            print(f"å®Ÿé¨“é–‹å§‹æ™‚é–“: {self.data['stats']['start_time']}")
        
        if '_total_time' in self.data.get('runner_data', {}):
            total_time = self.data['runner_data']['_total_time']
            print(f"ç·å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’ ({total_time/60:.1f}åˆ†)")
        
        print("\nğŸ“Š ROC-AUCã‚¹ã‚³ã‚¢çµ±è¨ˆ:")
        print(f"  æœ€é«˜: {self.trials_df['final_roc_auc'].max():.4f}")
        print(f"  æœ€ä½: {self.trials_df['final_roc_auc'].min():.4f}")
        print(f"  å¹³å‡: {self.trials_df['final_roc_auc'].mean():.4f}")
        print(f"  æ¨™æº–åå·®: {self.trials_df['final_roc_auc'].std():.4f}")
        print(f"  ä¸­å¤®å€¤: {self.trials_df['final_roc_auc'].median():.4f}")
        
        print("\nâ±ï¸  å­¦ç¿’æ™‚é–“çµ±è¨ˆ:")
        print(f"  æœ€é•·: {self.trials_df['training_time_s'].max():.2f}ç§’")
        print(f"  æœ€çŸ­: {self.trials_df['training_time_s'].min():.2f}ç§’")
        print(f"  å¹³å‡: {self.trials_df['training_time_s'].mean():.2f}ç§’")
        
        print("\nğŸ”§ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åˆ†å¸ƒ:")
        print(f"  ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {self.trials_df['optimizer'].value_counts().to_dict()}")
        print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {sorted(self.trials_df['batch_size'].unique())}")
        print(f"  å­¦ç¿’ç‡ç¯„å›²: {self.trials_df['learning_rate'].min():.6f} - {self.trials_df['learning_rate'].max():.6f}")
        print(f"  ã‚¨ãƒãƒƒã‚¯æ•°ç¯„å›²: {self.trials_df['max_epochs'].min()} - {self.trials_df['max_epochs'].max()}")
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆ
        print("\nğŸ¤– ãƒ¢ãƒ‡ãƒ«åˆ¥çµ±è¨ˆ:")
        for model in self.trials_df['model_name'].unique():
            model_data = self.trials_df[self.trials_df['model_name'] == model]
            print(f"  {model}:")
            print(f"    è©¦è¡Œæ•°: {len(model_data)}")
            print(f"    å¹³å‡ROC-AUC: {model_data['final_roc_auc'].mean():.4f}")
            print(f"    æœ€é«˜ROC-AUC: {model_data['final_roc_auc'].max():.4f}")
    
    def get_best_trial(self):
        """æœ€é«˜æ€§èƒ½ã®è©¦è¡Œã‚’è¡¨ç¤º"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        best_idx = self.trials_df['final_roc_auc'].idxmax()
        best_trial = self.trials_df.iloc[best_idx]
        
        print("\nğŸ† æœ€é«˜æ€§èƒ½ã®è©¦è¡Œ:")
        print(f"Trial ID: {best_trial['trial_id']}")
        print(f"ROC-AUC: {best_trial['final_roc_auc']:.4f}")
        print(f"å­¦ç¿’ç‡: {best_trial['learning_rate']:.6f}")
        print(f"ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {best_trial['optimizer']}")
        print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {best_trial['batch_size']}")
        print(f"ã‚¨ãƒãƒƒã‚¯æ•°: {best_trial['max_epochs']}")
        print(f"ãƒ¢ãƒ‡ãƒ«: {best_trial['model_name']}")
        print(f"å­¦ç¿’æ™‚é–“: {best_trial['training_time_s']:.2f}ç§’")
        print(f"ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°: {best_trial['final_iteration']}")
        
        return best_trial
    
    def get_worst_trial(self):
        """æœ€ä½æ€§èƒ½ã®è©¦è¡Œã‚’è¡¨ç¤º"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        worst_idx = self.trials_df['final_roc_auc'].idxmin()
        worst_trial = self.trials_df.iloc[worst_idx]
        
        print("\nğŸ’” æœ€ä½æ€§èƒ½ã®è©¦è¡Œ:")
        print(f"Trial ID: {worst_trial['trial_id']}")
        print(f"ROC-AUC: {worst_trial['final_roc_auc']:.4f}")
        print(f"å­¦ç¿’ç‡: {worst_trial['learning_rate']:.6f}")
        print(f"ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {worst_trial['optimizer']}")
        print(f"ãƒãƒƒãƒã‚µã‚¤ã‚º: {worst_trial['batch_size']}")
        print(f"ãƒ¢ãƒ‡ãƒ«: {worst_trial['model_name']}")
        
        return worst_trial
    
    def analyze_hyperparameters(self):
        """ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŠ¹æœã‚’åˆ†æ"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("\nğŸ“ˆ ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹æœåˆ†æ:")
        
        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶åˆ¥åˆ†æ
        print("\nğŸ”„ ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶åˆ¥æ€§èƒ½:")
        optimizer_stats = self.trials_df.groupby('optimizer')['final_roc_auc'].agg([
            'count', 'mean', 'std', 'min', 'max'
        ]).round(4)
        print(optimizer_stats)
        
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ¥åˆ†æ
        print("\nğŸ“¦ ãƒãƒƒãƒã‚µã‚¤ã‚ºåˆ¥æ€§èƒ½:")
        batch_stats = self.trials_df.groupby('batch_size')['final_roc_auc'].agg([
            'count', 'mean', 'std', 'min', 'max'
        ]).round(4)
        print(batch_stats)
        
        # ãƒ¢ãƒ‡ãƒ«åˆ¥åˆ†æ
        print("\nğŸ¤– ãƒ¢ãƒ‡ãƒ«åˆ¥æ€§èƒ½:")
        model_stats = self.trials_df.groupby('model_name')['final_roc_auc'].agg([
            'count', 'mean', 'std', 'min', 'max'
        ]).round(4)
        print(model_stats)
        
        # å­¦ç¿’ç‡ã¨æ€§èƒ½ã®ç›¸é–¢
        correlation = self.trials_df['learning_rate'].corr(self.trials_df['final_roc_auc'])
        print(f"\nğŸ“Š å­¦ç¿’ç‡ã¨ROC-AUCã®ç›¸é–¢ä¿‚æ•°: {correlation:.4f}")
        
        # ã‚¨ãƒãƒƒã‚¯æ•°ã¨æ€§èƒ½ã®ç›¸é–¢
        correlation_epochs = self.trials_df['max_epochs'].corr(self.trials_df['final_roc_auc'])
        print(f"ğŸ“Š ã‚¨ãƒãƒƒã‚¯æ•°ã¨ROC-AUCã®ç›¸é–¢ä¿‚æ•°: {correlation_epochs:.4f}")
    
    def get_top_trials(self, n=5):
        """ä¸Šä½nå€‹ã®è©¦è¡Œã‚’è¡¨ç¤º"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        top_trials = self.trials_df.nlargest(n, 'final_roc_auc')
        
        print(f"\nğŸ… ä¸Šä½{n}ä½ã®è©¦è¡Œ:")
        for i, (_, trial) in enumerate(top_trials.iterrows(), 1):
            print(f"\n{i}ä½: Trial {trial['trial_id']}")
            print(f"  ROC-AUC: {trial['final_roc_auc']:.4f}")
            print(f"  å­¦ç¿’ç‡: {trial['learning_rate']:.6f}")
            print(f"  ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {trial['optimizer']}")
            print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {trial['batch_size']}")
            print(f"  ãƒ¢ãƒ‡ãƒ«: {trial['model_name']}")
        
        return top_trials
    
    def analyze_convergence(self):
        """åæŸæ€§ã‚’åˆ†æ"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("\nğŸ“‰ åæŸæ€§åˆ†æ:")
        
        # æ—©æœŸçµ‚äº†ã—ãŸè©¦è¡Œã®åˆ†æ
        completed_trials = self.trials_df[self.trials_df['status'] == 'TERMINATED']
        print(f"å®Œäº†ã—ãŸè©¦è¡Œæ•°: {len(completed_trials)}")
        
        # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã®çµ±è¨ˆ
        print(f"\nã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°çµ±è¨ˆ:")
        print(f"  å¹³å‡: {self.trials_df['final_iteration'].mean():.1f}")
        print(f"  æœ€å¤§: {self.trials_df['final_iteration'].max()}")
        print(f"  æœ€å°: {self.trials_df['final_iteration'].min()}")
        
        # æ€§èƒ½å‘ä¸Šã®å‚¾å‘
        trials_by_time = self.trials_df.sort_values('training_time_s')
        running_max = trials_by_time['final_roc_auc'].expanding().max()
        improvement_rate = (running_max.iloc[-1] - running_max.iloc[0]) / len(trials_by_time)
        print(f"\næ€§èƒ½å‘ä¸Šç‡ï¼ˆè©¦è¡Œã‚ãŸã‚Šï¼‰: {improvement_rate:.6f}")
    
    def save_to_csv(self, output_path="hpo_results.csv"):
        """çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        self.trials_df.to_csv(output_path, index=False, encoding='utf-8')
        print(f"âœ“ çµæœã‚’ {output_path} ã«ä¿å­˜ã—ã¾ã—ãŸ")
    
    def get_all_trials(self):
        """å…¨è©¦è¡Œã®DataFrameã‚’è¡¨ç¤º"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("\nğŸ“‹ å…¨è©¦è¡Œãƒ‡ãƒ¼ã‚¿:")
        # é‡è¦ãªåˆ—ã®ã¿ã‚’è¡¨ç¤º
        display_cols = ['trial_id', 'final_roc_auc', 'learning_rate', 'optimizer', 
                       'batch_size', 'model_name', 'training_time_s']
        print(self.trials_df[display_cols].to_string(index=False))
        
        return self.trials_df
    
    def create_insights_report(self):
        """æ´å¯Ÿãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("\n" + "="*60)
        print("ğŸ” HPOå®Ÿé¨“æ´å¯Ÿãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*60)
        
        # 1. æœ€é©ãªãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®çµ„ã¿åˆã‚ã›
        best_trial = self.trials_df.loc[self.trials_df['final_roc_auc'].idxmax()]
        print(f"\nâœ¨ æ¨å¥¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
        print(f"  å­¦ç¿’ç‡: {best_trial['learning_rate']:.6f}")
        print(f"  ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {best_trial['optimizer']}")
        print(f"  ãƒãƒƒãƒã‚µã‚¤ã‚º: {best_trial['batch_size']}")
        print(f"  ãƒ¢ãƒ‡ãƒ«: {best_trial['model_name']}")
        print(f"  â†’ æœŸå¾…æ€§èƒ½: {best_trial['final_roc_auc']:.4f} ROC-AUC")
        
        # 2. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ¹ç‡æ€§
        efficiency = self.trials_df['final_roc_auc'] / self.trials_df['training_time_s']
        best_efficiency_idx = efficiency.idxmax()
        efficient_trial = self.trials_df.loc[best_efficiency_idx]
        
        print(f"\nâš¡ æœ€ã‚‚åŠ¹ç‡çš„ãªè¨­å®š:")
        print(f"  Trial ID: {efficient_trial['trial_id']}")
        print(f"  ROC-AUC: {efficient_trial['final_roc_auc']:.4f}")
        print(f"  å­¦ç¿’æ™‚é–“: {efficient_trial['training_time_s']:.1f}ç§’")
        print(f"  åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢: {efficiency[best_efficiency_idx]:.6f}")
        
        # 3. æ³¨æ„ã™ã¹ãè¨­å®š
        worst_trials = self.trials_df.nsmallest(3, 'final_roc_auc')
        print(f"\nâš ï¸  é¿ã‘ã‚‹ã¹ãè¨­å®šãƒ‘ã‚¿ãƒ¼ãƒ³:")
        common_bad_optimizers = worst_trials['optimizer'].mode()
        if len(common_bad_optimizers) > 0:
            print(f"  ä½æ€§èƒ½ã§ã‚ˆãè¦‹ã‚‰ã‚Œã‚‹ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {common_bad_optimizers[0]}")
        
        # 4. å®‰å®šæ€§åˆ†æ
        optimizer_stability = self.trials_df.groupby('optimizer')['final_roc_auc'].std()
        most_stable = optimizer_stability.idxmin()
        print(f"\nğŸ¯ æœ€ã‚‚å®‰å®šã—ãŸã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {most_stable} (æ¨™æº–åå·®: {optimizer_stability[most_stable]:.4f})")
    
    def analyze_learning_rate_ranges(self):
        """å­¦ç¿’ç‡ç¯„å›²åˆ¥ã®æ€§èƒ½åˆ†æ"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("\nğŸ“ˆ å­¦ç¿’ç‡ç¯„å›²åˆ¥æ€§èƒ½åˆ†æ:")
        
        # å­¦ç¿’ç‡ã‚’ç¯„å›²åˆ¥ã«åˆ†é¡
        lr_ranges = [
            (0, 0.001, "ä½å­¦ç¿’ç‡ (< 0.001)"),
            (0.001, 0.003, "ä¸­å­¦ç¿’ç‡ (0.001-0.003)"),
            (0.003, 0.01, "é«˜å­¦ç¿’ç‡ (> 0.003)")
        ]
        
        for min_lr, max_lr, label in lr_ranges:
            range_trials = self.trials_df[
                (self.trials_df['learning_rate'] >= min_lr) & 
                (self.trials_df['learning_rate'] < max_lr)
            ]
            
            if len(range_trials) > 0:
                print(f"\n{label}:")
                print(f"  è©¦è¡Œæ•°: {len(range_trials)}")
                print(f"  å¹³å‡ROC-AUC: {range_trials['final_roc_auc'].mean():.4f}")
                print(f"  æœ€é«˜ROC-AUC: {range_trials['final_roc_auc'].max():.4f}")
                print(f"  æœ€ä½ROC-AUC: {range_trials['final_roc_auc'].min():.4f}")
    
    def compare_model_performance(self):
        """ãƒ¢ãƒ‡ãƒ«é–“ã®è©³ç´°ãªæ€§èƒ½æ¯”è¼ƒ"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("\nğŸ¤– ãƒ¢ãƒ‡ãƒ«è©³ç´°æ¯”è¼ƒ:")
        
        for model in self.trials_df['model_name'].unique():
            model_trials = self.trials_df[self.trials_df['model_name'] == model]
            model_short = model.split('.')[0]  # ãƒ¢ãƒ‡ãƒ«åã‚’çŸ­ç¸®
            
            print(f"\n{model_short}:")
            print(f"  è©¦è¡Œæ•°: {len(model_trials)}")
            print(f"  å¹³å‡ROC-AUC: {model_trials['final_roc_auc'].mean():.4f}")
            print(f"  æœ€é«˜ROC-AUC: {model_trials['final_roc_auc'].max():.4f}")
            print(f"  å¹³å‡å­¦ç¿’æ™‚é–“: {model_trials['training_time_s'].mean():.2f}ç§’")
            print(f"  æœ€é©å­¦ç¿’ç‡: {model_trials.loc[model_trials['final_roc_auc'].idxmax(), 'learning_rate']:.6f}")
    
    def generate_executive_summary(self):
        """ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        if self.trials_df is None:
            print("ã¾ãšextract_trials_data()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
            return
        
        print("\n" + "="*60)
        print("ğŸ“‹ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼")
        print("="*60)
        
        best_trial = self.trials_df.loc[self.trials_df['final_roc_auc'].idxmax()]
        
        print(f"\nğŸ¯ ã‚­ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ³ãƒ‡ã‚£ãƒ³ã‚°:")
        print(f"  â€¢ æœ€é«˜æ€§èƒ½: {best_trial['final_roc_auc']:.4f} ROC-AUC")
        print(f"  â€¢ æœ€é©å­¦ç¿’ç‡: {best_trial['learning_rate']:.6f}")
        print(f"  â€¢ æ¨å¥¨ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶: {best_trial['optimizer']}")
        print(f"  â€¢ æ¨å¥¨ãƒãƒƒãƒã‚µã‚¤ã‚º: {best_trial['batch_size']}")
        print(f"  â€¢ æœ€é©ãƒ¢ãƒ‡ãƒ«: {best_trial['model_name'].split('.')[0]}")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†å¸ƒ
        high_perf_count = len(self.trials_df[self.trials_df['final_roc_auc'] > 0.9])
        low_perf_count = len(self.trials_df[self.trials_df['final_roc_auc'] < 0.5])
        
        print(f"\nğŸ“Š æ€§èƒ½åˆ†å¸ƒ:")
        print(f"  â€¢ é«˜æ€§èƒ½è©¦è¡Œ (ROC-AUC > 0.9): {high_perf_count}/{len(self.trials_df)} ({high_perf_count/len(self.trials_df)*100:.1f}%)")
        print(f"  â€¢ ä½æ€§èƒ½è©¦è¡Œ (ROC-AUC < 0.5): {low_perf_count}/{len(self.trials_df)} ({low_perf_count/len(self.trials_df)*100:.1f}%)")
        
        # åŠ¹ç‡æ€§
        efficiency = self.trials_df['final_roc_auc'] / self.trials_df['training_time_s']
        best_efficiency_trial = self.trials_df.loc[efficiency.idxmax()]
        
        print(f"\nâš¡ åŠ¹ç‡æ€§:")
        print(f"  â€¢ æœ€åŠ¹ç‡è©¦è¡Œ: {best_efficiency_trial['trial_id']}")
        print(f"  â€¢ åŠ¹ç‡æ€§ã‚¹ã‚³ã‚¢: {efficiency.max():.6f}")
        print(f"  â€¢ å¹³å‡å­¦ç¿’æ™‚é–“: {self.trials_df['training_time_s'].mean():.2f}ç§’")
        
        print(f"\nğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        print(f"  1. å­¦ç¿’ç‡ {best_trial['learning_rate']:.6f} ã‚’åŸºæº–å€¤ã¨ã—ã¦ä½¿ç”¨")
        print(f"  2. {best_trial['optimizer']} ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼ã‚’æ¡ç”¨æ¨å¥¨")
        print(f"  3. ãƒãƒƒãƒã‚µã‚¤ã‚º {best_trial['batch_size']} ã§æœ¬ç•ªå®Ÿè£…")
        print(f"  4. {best_trial['model_name'].split('.')[0]} ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ")
        print(f"  5. å­¦ç¿’æ™‚é–“åŠ¹ç‡ã‚’é‡è¦–ã™ã‚‹å ´åˆã¯ Trial {best_efficiency_trial['trial_id']} ã®è¨­å®šã‚’æ¤œè¨")


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    # HPODataExtractorã®ä½¿ç”¨ä¾‹
    extractor = HPODataExtractor("step2_result_adamw/experiment_state-2025-07-06_12-03-57.json")
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨æŠ½å‡º
    if extractor.load_data():
        df = extractor.extract_trials_data()
        
        # å„ç¨®åˆ†æã®å®Ÿè¡Œ
        extractor.get_summary()
        extractor.get_best_trial()
        extractor.get_worst_trial()
        extractor.analyze_hyperparameters()
        extractor.analyze_convergence()
        extractor.get_top_trials(5)
        extractor.create_insights_report()
        
        # çµæœã‚’CSVã«ä¿å­˜
        extractor.save_to_csv("hpo_analysis_results.csv")
        
        print(f"\nâœ… åˆ†æå®Œäº†ï¼æŠ½å‡ºã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã¯ {len(df)} è¡Œã§ã™ã€‚")